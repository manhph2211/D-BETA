{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_hdf5 = 'data/downstream/code-test/data/ecg_tracings.hdf5'\n",
    "\n",
    "with h5py.File(path_to_hdf5, 'r') as hdf:\n",
    "    tracings = hdf['tracings'][:] \n",
    "    print(\"Original shape:\", tracings.shape)  # (827, 4096, 12)\n",
    "    original_samples = tracings.shape[1] \n",
    "    resampled_samples = int(original_samples * (500 / 400)) \n",
    "    resampled_tracings = np.array([resample(tracing, resampled_samples, axis=0).T for tracing in tracings])    \n",
    "    truncated_tracings = resampled_tracings[:, :, :5000]\n",
    "    print(\"Truncated shape:\", truncated_tracings.shape)  # (827, 5000, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "leads = ['I', 'II', 'III', 'aVR', 'aVF', 'aVL', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "ecg = truncated_tracings[np.random.randint(len(truncated_tracings))]\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 10))\n",
    "for i in range(12):\n",
    "    ax = axs[i // 4, i % 4]\n",
    "    ax.plot(ecg[i, :])\n",
    "    ax.set_title(leads[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_labels = '1AVB,RBBB,LBBB,SB,AFIB,ST'.split(\",\")\n",
    "\n",
    "with open(\"configs/LLMTexts.json\", 'r') as file:\n",
    "    converting_tool = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_roc_auc(y_true, y_pred, model_name):\n",
    "    roc_auc = []\n",
    "    for i in range(y_true.shape[1]): \n",
    "        auc = roc_auc_score(y_true[:, i], y_pred[:, i], average='macro', multi_class='ovo')\n",
    "        roc_auc.append(auc)\n",
    "    print(f\"ROC AUC scores for {model_name}: {np.mean(roc_auc)}\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = 'data/downstream/code-test/data/annotations/gold_standard.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "diagnoses_test = df.values \n",
    "\n",
    "y_true = pd.read_csv('data/downstream/code-test/data/annotations/gold_standard.csv').values\n",
    "y_cardio = pd.read_csv('data/downstream/code-test/data/annotations/cardiology_residents.csv').values\n",
    "y_emerg = pd.read_csv('data/downstream/code-test/data/annotations/emergency_residents.csv').values\n",
    "y_student = pd.read_csv('data/downstream/code-test/data/annotations/medical_students.csv').values\n",
    "y_neuralnet = pd.read_csv('data/downstream/code-test/data/annotations/dnn.csv', usecols=range(1, 7)).values\n",
    "\n",
    "model_names = [\"Fully Trained DNN\", \"Cardiology Residents\", \"Emergency Residents\", \"Medical Students\"]\n",
    "model_predictions = [y_neuralnet, y_cardio, y_emerg, y_student]\n",
    "\n",
    "for model_name, y_pred in zip(model_names, model_predictions):\n",
    "    compute_roc_auc(y_true, y_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "from transformers import T5TokenizerFast\n",
    "from models.dbeta import DBETA\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "def load_encoders(checkpoint_path=\"checkpoints/best.pt\"):\n",
    "    with open('configs/config.json', 'r') as json_file:\n",
    "        cfg = json.load(json_file)\n",
    "\n",
    "    cfg = SimpleNamespace(**cfg['model'])\n",
    "    model = DBETA(cfg)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    if \"ecg_encoder.mask_emb\" in checkpoint[\"model\"].keys():\n",
    "        del checkpoint[\"model\"][\"ecg_encoder.mask_emb\"]\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model\"], strict=True)\n",
    "    model.eval()\n",
    "    return model, model.ecg_encoder, model.language_encoder, model.unimodal_ecg_pooler, model.unimodal_language_pooler, model.multi_modal_ecg_proj, model.multi_modal_language_proj, model.class_embedding\n",
    "\n",
    "\n",
    "def extract_language_features(model, texts, pooler=None, proj=None):\n",
    "    model_name = \"google/flan-t5-base\"\n",
    "    tokenizer = T5TokenizerFast.from_pretrained( \n",
    "            model_name, do_lower_case=\"uncased\" in model_name\n",
    "        ) \n",
    "    features_dict = {}\n",
    "    \n",
    "    for text in tqdm(texts):\n",
    "        encoded_input = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)[0]\n",
    "            outputs = proj(outputs)\n",
    "            if pooler is None:\n",
    "                max_pooled_features, _ = torch.max(outputs, dim=1)  \n",
    "            else:\n",
    "                max_pooled_features = pooler(outputs)\n",
    "            \n",
    "            features_dict[text] = max_pooled_features.numpy().squeeze(0)\n",
    "\n",
    "    print(\"Successfully Extracted Language Features !!!\")\n",
    "    \n",
    "    return features_dict\n",
    "    \n",
    "    \n",
    "def extract_ecg_features(model, ecgs, pooler=None, proj=None, class_embedding=None, batch_size=100):\n",
    "    features = []\n",
    "    num_ecgs = len(ecgs)\n",
    "    padding_mask = torch.zeros(batch_size, 12, 5000, dtype=torch.bool)\n",
    "    \n",
    "    for start_idx in tqdm(range(0, num_ecgs, batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, num_ecgs)\n",
    "        ecg_batch = torch.tensor(ecgs[start_idx:end_idx], dtype=torch.float32)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            uni_modal_ecg_feats, ecg_padding_mask = (\n",
    "                model.get_embeddings(ecg_batch, padding_mask=None)\n",
    "            )\n",
    "            \n",
    "            cls_emb = class_embedding.repeat((len(uni_modal_ecg_feats), 1, 1))\n",
    "            uni_modal_ecg_feats = torch.cat([cls_emb, uni_modal_ecg_feats], dim=1)\n",
    "            uni_modal_ecg_feats = model.get_output(uni_modal_ecg_feats, ecg_padding_mask)\n",
    "            out = proj(uni_modal_ecg_feats)\n",
    "            ecg_features = pooler(out)\n",
    "            \n",
    "            features.append(ecg_features.numpy())\n",
    "            \n",
    "    print(\"Successfully Extract Features !!!\")\n",
    "    \n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "\n",
    "def zero_shot(checkpoint_path, model_name=None):\n",
    "    print(f\"Evaluating {model_name} ...\")\n",
    "    model, ecg_model, language_model, unimodal_ecg_pooler, unimodal_language_pooler, multi_modal_ecg_proj, multi_modal_language_proj, class_embedding = load_encoders(checkpoint_path)\n",
    "    potential_labels = [converting_tool[i].lower() for i in all_labels]\n",
    "    potential_language_features_dict = extract_language_features(language_model, potential_labels, unimodal_language_pooler, multi_modal_language_proj)\n",
    "    ecg_features = extract_ecg_features(ecg_model, truncated_tracings, unimodal_ecg_pooler, multi_modal_ecg_proj, class_embedding, batch_size=100)   \n",
    "\n",
    "    all_similarities = []\n",
    "    all_actual_labels = []\n",
    "    \n",
    "    for i, ecg_feature in tqdm(enumerate(ecg_features)):\n",
    "        ecg_feature = torch.tensor(ecg_feature)\n",
    "\n",
    "        similarities = []\n",
    "        for _, potential_feature in potential_language_features_dict.items():\n",
    "            potential_feature = torch.tensor(potential_feature).reshape(1, -1)\n",
    "            ecg_feature = ecg_feature.reshape(1, -1)\n",
    "            sim_score = ecg_feature @ potential_feature.T\n",
    "            similarities.append(sim_score[0][0].item())\n",
    "        \n",
    "        all_similarities.append(similarities)\n",
    "\n",
    "    all_similarities = np.array(all_similarities)\n",
    "    \n",
    "    all_actual_labels = np.array(diagnoses_test)\n",
    "\n",
    "    n_classes = 6\n",
    "    \n",
    "    aucs = []\n",
    "    for i in range(n_classes):\n",
    "        auc = roc_auc_score(all_actual_labels[:, i], all_similarities[:, i], average='macro', multi_class='ovo')\n",
    "        aucs.append(auc)\n",
    "        print(f\"AUC at class {all_labels[i]}: \", auc)\n",
    "    \n",
    "    average_auc = np.mean(aucs)\n",
    "    print(f\"Zero-shot classification AUC: {average_auc:.4f}\")\n",
    "    \n",
    "    return average_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best ...\n"
     ]
    }
   ],
   "source": [
    "average_auc = zero_shot(\"checkpoints/sample.pt\", \"sample\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
